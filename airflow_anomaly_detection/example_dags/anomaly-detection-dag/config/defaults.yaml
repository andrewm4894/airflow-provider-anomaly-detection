# general defaults you might want to apply to each metric batch.
# you can overwrite the defaults by defining whatever you want in <metric-batch>.yaml files.
dag_name_prefix: anomalydetection_ # a useful prefix for the dags created by this provider.
gcp_connection_id: google_cloud_default # a gcp connection to use.
gcp_destination_dataset: metrics # dataset name to write metrics to.
gcp_ingest_destination_table_name: metrics # table name to write metrics to.
gcp_score_destination_table_name: metrics_scored # table name to write scored metrics to.
gcs_model_bucket: some-gcs-bucket # a gcs bucket where trained models will be stored, one per metric.
alert_emails_to: youremail@example.com # where you want alert emails to be sent.
graph_symbol: '~'
anomaly_symbol: '* '
normal_symbol: '  '
# below params might be better set in <metric-batch>.yaml specifc config files
# airflow_ingest_schedule_interval: '5 * * * *'
# airflow_training_schedule_interval: '30 8 * * *'
# airflow_scoring_schedule_interval: '10 * * * *'
# airflow_alerting_schedule_interval: '15 * * * *'
# airflow_start_date: '2023-01-16'
# train_max_n: 720
# train_max_n_days_ago: 30
# preprocess_n_lags: 2
# score_max_n: 1
# score_max_n_days_ago: 7
# alert_smooth_n: 3
# alert_status_threshold: 0.90
# alert_max_n: 72
# alert_max_n_days_ago: 7
# alert_window_last_n: 12